# Week 3, Lecture 2

## Kruskals Algorithm

### Minimum Spanning Tree (MST)

A minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. That is, it is a spanning tree whose sum of edge weights is as small as possible.

### Tree

- A tree on n nodes has n − 1 edges.
- Any connected, undirected graph G = (V, E ) with |E | = |V | − 1 is a tree.
- An undirected graph is a tree if and only if there is a unique path between any pair of nodes.


Kruskal’s minimum spanning tree algorithm starts with the empty graph and then selects edges from E according to the following rule: Repeatedly add the next lightest edge that doesn’t produce a cycle.

It constructs the tree edge by edge and, by simply picking whichever edge is cheapest at the moment (that doesn't form a cycle). This is a greedy algorithm: every decision it makes is the one with the immediate advantage.

### Cut property

The correctness of not only Kruskals but also many other minimum spanning tree algorithms is justified by the cut property.
The cut property states that:

**Suppose edges X are part of a minimum spanning tree of G = (V, E ).
Pick any subset of nodes S for which X does not cross between S and V − S, and let
e be the lightest edge across this partition. Then X ∪ {e} is part of some MST.**

#### Proof:
<pre>
Edges X are part of some MST T; if the new edge e also happens to be part of T, then the theorem is proved by definition. So assume e is not in T.
Add edge e to T. Since T is connected, it already has a path between the endpoints of e, so adding e creates a cycle. This cycle must also have some other edge e' across the cut (S, V − S). If we now remove this edge, we are left with T' = T ∪ {e} − {e'}.
T' is connected since e' is a cycle edge. Also, it has the same number of edges as T. Hence, T' is a tree.

Also, weight(T') = weight(T) + w(e) − w(e')
Both e and e' cross between S and V − S, and e is specifically the lightest edge of
this type. Therefore w(e) ≤ w(e'), and weight(T') ≤ weight(T). Since T is an MST,
it must be the case that weight(T') = weight(T) and that T' is also an MST.
</pre>

### Kruskal’s minimum spanning tree algorithm

```python
procedure kruskal (G, w)
Input: A connected undirected graph G = (V, E) with edge weights w e
output: A minimum spanning three defined by the edges X
for all u ∈V:
  makeset (u)
X = {}
sort the edges E by weight
for all edges {u, v} ∈ E, in increasing order of weight:
  if find(u) ≠ find(v):
    add edge {u, v} to X
    union(u, v)
```
<pre>
At any given moment, the edges the algorithm has already chosen form a partial solution, a collection of connected components each of which has a tree structure. The next edge e to be added connects two of these components; call them T<sub>1</sub> and T<sub>2</sub>. Since e is the lightest edge that doesn’t produce a cycle, it is certain to be the lightest edge between T<sub>1</sub> and V − T<sub>1</sub> and therefore satisfies the cut property.

At each stage, the algorithm chooses an edge to add to its current partial solution. To do so, it needs to test each candidate edge u − v to see whether the endpoints u and v lie in different components; otherwise the edge produces a cycle. And once an edge is chosen, the corresponding components need to be merged.

We will model the algorithm’s state as a collection of disjoint sets, each of which
contains the nodes of a particular component. Initially each node is in a component
by itself:

makeset(x): create a singleton set containing just x.
We repeatedly test pairs of nodes to see if they belong to the same set.

find(x): to which set does x belong?
And whenever we add an edge, we are merging two components.

union(x, y): merge the sets containing x and y.

It uses |V| makeset, 2|E | find, and |V| − 1 union operations.
</pre>

#### Union by Rank: (Disjoint-Sets data structure)

One way to store a set is as a directed tree. Nodes of the tree are elements of the set, arranged in no particular order, and each has parent pointers that eventually lead up to the root of the tree. This root element is a convenient representative for the set. It is distinguished from the other elements by the fact that its parent pointer is a self-loop. In addition to a parent pointer π, each node also has a rank:

```python
procedure makeset(x)
π(x) = x
rank(x) = 0
function find(x)
while x != π(x) : x = π(x)
return x
```

Merging two sets: make the root of one point to the root of the other. Since tree height is the main impediment to computational efficiency, a good strategy is to make the root of the shorter tree point to the root of the taller tree. This way, the overall height increases only if the two trees being merged are equally tall. Instead of explicitly computing heights of trees, we will use the rank numbers of their root nodes.
<pre>
procedure union(x, y):
r<sub>x</sub> = find(x)
r<sub>y</sub> = find(y)
if r<sub>x</sub> = r<sub>y</sub> : return
if rank(r<sub>x</sub>) > rank(r<sub>y</sub>):
π(r<sub>y</sub>) = r<sub>x</sub>
else:
π(r<sub>x</sub>) = r<sub>y</sub>
if rank(r<sub>x</sub>) = rank(r<sub>y</sub>) : rank(<sub>y</sub>) = rank(r<sub>y</sub>) + 1
</pre>
##### Rank:

The rank of a node is exactly the height of the subtree rooted at that node.

- For any x, rank(x) < rank(π (x))
- Any root node of rank k has at least 2<sup>k</sup> nodes in its tree.
- If there are n elements overall, there can be at most n/(2<sup>k</sup>) nodes of rank k.

With this, the total time for Kruskal’s algorithm becomes O(|E | log |V|) for sorting the edges plus another O(|E | log |V|) for the union and find operations that dominate the rest of the algorithm.

#### Path Compression:
<pre>
During each find, when a series of parent pointers is followed up to the root of a tree, we will change all these pointers so that they point directly to the root.
The benefit of this simple alteration is long-term rather than instantaneous and thus
necessitates a particular kind of analysis: we need to look at sequences of find and
union operations, starting from an empty data structure, and determine the average
time per operation. This amortized cost turns out to be just barely more than O(1),
down from the earlier O(log n)
</pre>
```python
function find(x)
if x != π(x) : π(x) = find(π (x))
return π (x)
```

Ranks are divided into log*n intervals: {1}, {2}, {3, 4}, {5, 6, . . . , 16}, {17, 18, . . . , 2<sup>16</sup> = 65536},....

Nodes x on the chain (to root) fall into two categories: 
1. The rank of parent(x) is in a higher interval than the rank of x,
2. The rank of parent(x) lies in the same interval as that of rank of x.

There are at most nlog*n nodes of the first type.

When x is of the second type, its parent changes to one of higher rank. Therefore, if x's rank lies in the interval {k+1, … 2<sup>k</sup>}, it is of this type at most 2<sup>k</sup> times before its parent's rank is in a higher interval, after which, it is never of the second type again.

Thus the overall time for m find’s is O(mlog*n) plus at most O(nlog*n),
(because n/2<sup>k+1</sup> + n/2<sup>k+2</sup> + .... <= n/2<sup>k</sup>)
<pre>
Thus, with path compression and Disjoint-Sets data structure, Kruskal's algorithm runs with time complexity:
"Sorting |E| elements” + O(|E| log|V|)
</pre>





